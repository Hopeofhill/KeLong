#!/usr/bin/env python3
"""
è°ƒè¯•sessionæ•°æ®é—®é¢˜

éªŒè¯å¼‚æ­¥åˆ†æç»“æœçš„sessionå­˜å‚¨å’Œè¯»å–é€»è¾‘
"""

import sys
import os
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/mnt/h/nnscholar-search-main')

def debug_session_data():
    """è°ƒè¯•sessionæ•°æ®å­˜å‚¨é—®é¢˜"""
    
    print("ğŸ” Sessionæ•°æ®è°ƒè¯•åˆ†æ")
    print("=" * 50)
    
    # æ£€æŸ¥å¼‚æ­¥ä»»åŠ¡å¤„ç†å™¨çš„ç»“æœæ ¼å¼
    print("\nğŸ“‹ æ£€æŸ¥å¼‚æ­¥ä»»åŠ¡å¤„ç†å™¨çš„ç»“æœæ ¼å¼:")
    
    from services.academic_analysis_handlers import handle_research_topic_analysis
    from services.async_task_service import AsyncTask, TaskStatus
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿä»»åŠ¡
    task_data = {
        'query': 'machine learning',
        'session_id': 'test_session_123'
    }
    
    # åˆ›å»ºAsyncTaskå®ä¾‹
    test_task = AsyncTask('test_task_id', 'research_topic_analysis', task_data)
    
    print(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {test_task.task_id}")
    print(f"ğŸ“ ä»»åŠ¡ç±»å‹: {test_task.task_type}")
    print(f"ğŸ“Š ä»»åŠ¡æ•°æ®: {test_task.task_data}")
    
    # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†ï¼ˆä¼šå¤±è´¥ï¼Œä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°é”™è¯¯ç»“æœçš„æ ¼å¼ï¼‰
    try:
        result = handle_research_topic_analysis(test_task)
        print(f"âœ… ä»»åŠ¡ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
    except Exception as e:
        print(f"âš ï¸  ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼ˆé¢„æœŸçš„ï¼‰: {e}")
        
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        print(f"ğŸ“‹ ä»»åŠ¡çŠ¶æ€: {test_task.status}")
        print(f"ğŸ“ˆ ä»»åŠ¡è¿›åº¦: {test_task.progress}%")
        print(f"ğŸ’¬ ä»»åŠ¡æ¶ˆæ¯: {test_task.message}")
        print(f"âŒ ä»»åŠ¡é”™è¯¯: {test_task.error}")
    
    print("\nğŸ”— æ£€æŸ¥APIè·¯ç”±çš„sessionå­˜å‚¨é€»è¾‘:")
    
    # æ£€æŸ¥è·¯ç”±æ–‡ä»¶ä¸­çš„session keyæ ¼å¼
    api_file = '/mnt/h/nnscholar-search-main/routes/api_routes.py'
    with open(api_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æŸ¥æ‰¾æ‰€æœ‰sessionå­˜å‚¨æ“ä½œ
    import re
    session_patterns = re.findall(r"session\['([^']+)'\]\s*=", content)
    
    print("ğŸ“š å‘ç°çš„session keys:")
    for i, key in enumerate(session_patterns, 1):
        print(f"  {i}. {key}")
    
    # æ£€æŸ¥æ–°æ—§APIçš„session keyå†²çª
    print("\nâš ï¸  æ½œåœ¨çš„session keyå†²çª:")
    async_keys = [key for key in session_patterns if 'result' in key]
    unique_keys = set(async_keys)
    
    for key in unique_keys:
        count = async_keys.count(key)
        if count > 1:
            print(f"  ğŸ”´ å†²çª: '{key}' è¢«ä½¿ç”¨äº† {count} æ¬¡")
        else:
            print(f"  ğŸŸ¢ æ­£å¸¸: '{key}' è¢«ä½¿ç”¨äº† {count} æ¬¡")
    
    print("\nğŸ¯ é—®é¢˜åˆ†æå’Œå»ºè®®:")
    print("1. æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—§çš„åŒæ­¥APIå’Œæ–°çš„å¼‚æ­¥APIä½¿ç”¨ç›¸åŒçš„session key")
    print("2. éªŒè¯sessionæ•°æ®çš„æ ¼å¼æ˜¯å¦ä¸€è‡´")
    print("3. ç¡®è®¤å‰ç«¯è·³è½¬æ—¶sessionæ•°æ®æ˜¯å¦æ­£ç¡®ä¼ é€’")
    
    # æ£€æŸ¥æ¨¡æ¿æœŸæœ›çš„æ•°æ®æ ¼å¼
    print("\nğŸ“„ æ£€æŸ¥æ¨¡æ¿æœŸæœ›çš„æ•°æ®æ ¼å¼:")
    template_file = '/mnt/h/nnscholar-search-main/templates/academic_analysis.html'
    with open(template_file, 'r', encoding='utf-8') as f:
        template_content = f.read()
    
    # æŸ¥æ‰¾æ¨¡æ¿ä¸­ä½¿ç”¨çš„å˜é‡
    template_vars = re.findall(r'\{\{\s*([^}]+)\s*\}\}', template_content)
    
    print("ğŸ“‹ æ¨¡æ¿ä¸­ä½¿ç”¨çš„å˜é‡:")
    for var in set(template_vars):
        var = var.strip()
        if not var.startswith('analysis_type') and not var.startswith('if') and not var.startswith('elif'):
            print(f"  - {var}")
    
    print("\nğŸ”§ å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ:")
    print("1. æ¸…ç†æ—§çš„åŒæ­¥APIä¸­çš„sessionå­˜å‚¨é€»è¾‘ï¼Œé¿å…å†²çª")
    print("2. ç¡®ä¿å¼‚æ­¥APIçš„ç»“æœæ ¼å¼å®Œå…¨ç¬¦åˆæ¨¡æ¿æœŸæœ›")
    print("3. æ·»åŠ sessionæ•°æ®éªŒè¯å’Œé»˜è®¤å€¼å¤„ç†")
    print("4. è€ƒè™‘åœ¨å‰ç«¯è·³è½¬å‰éªŒè¯sessionæ•°æ®çš„å®Œæ•´æ€§")

if __name__ == "__main__":
    debug_session_data()